{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mdxplain Tutorial 1: Introduction to Conformational Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Proteins are dynamic molecules that sample multiple conformational states during their lifespan. Understanding which conformations exist and what distinguishes them at the molecular level is crucial for comprehending protein mechanisms.\n",
    "The challenge in analyzing molecular dynamics (MD) trajectories lies in extracting biologically meaningful conformational states from thousands of simulation frames. Traditional approaches often require manual selection of collective variables or a priori knowledge of relevant structural features.\n",
    "\n",
    "This tutorial demonstrates mdxplain an automated pipeline builder that can be used to identify distinct conformational states and determines the specific residue-residue contacts that characterize each state. The approach combines machine learning techniques with structural biology principles to transform high-dimensional trajectory data into interpretable biological insights.\n",
    "\n",
    "### Methodology Overview\n",
    "\n",
    "The pipeline addresses key challenges in conformational analysis:\n",
    "\n",
    "1. **Feature Engineering**: Convert atomic coordinates to rotation/translation-invariant contact descriptors\n",
    "2. **Dimensionality Reduction**: Overcome the curse of dimensionality for clustering in high-dimensional spaces\n",
    "3. **State Identification**: Determine the number and boundaries of conformational states\n",
    "4. **State Characterization**: Identify which molecular interactions distinguish each state\n",
    "\n",
    "### Test System\n",
    "\n",
    "We analyze the Villin headpiece (PDB: 2RJY [1]), a 64-residue protein domain that serves often as a model system for protein folding studies [2-7]. The trajectory contains 9,368 frames (9368 ns) with 1,027 atoms.\n",
    "\n",
    "The complete analysis requires 14 lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n",
    "\n",
    "We just need to import one thing. Just the PipelineManager. The whole analysis can be managed from here. We do not need other stuff.\n",
    "\n",
    "## Design note\n",
    "\n",
    "Pipeline Builder Module\n",
    "- We use a builder pattern: the PipelineManager incrementally constructs an internal PipelineData structure.\n",
    "\n",
    "- Everything is centralized in `pipeline.data` and is enriched by the modules (trajectory, feature, feature_selector, decomposition, clustering, data_selector, comparison, feature_importance).\n",
    "\n",
    "Analysis module\n",
    "- The `analysis` module reads from `pipeline.data`.\n",
    "- It supports statistical analyses on features and structural analyses on trajectories such as RMSD and RMSF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdxplain import PipelineManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "### Step 1: Data Loading and Preprocessing\n",
    "\n",
    "Efficient data handling is essential for processing large MD trajectories. Memory mapping allows analysis of datasets larger than available RAM by loading only required data sections. Residue labeling provides metadata necessary for interpreting structural features.\n",
    "\n",
    "Note on memory mapping (memmap) and chunk sizing\n",
    "- What memmap is: Arrays are kept on disk and only the required slices are loaded into RAM on demand. This keeps the memory footprint low at the cost of extra I/O.\n",
    "- When to enable memmap (use_memmap=True):\n",
    "  - Trajectories that approach/exceed available RAM\n",
    "  - Multiple trajectories opened at once\n",
    "  - Interactive analysis on laptops/workstations with limited memory\n",
    "- When to disable memmap (use_memmap=False):\n",
    "  - Small/medium datasets that comfortably fit in RAM\n",
    "  - You need maximum speed and have ample memory (e.g., HPC node)\n",
    "  - You are on a slow or remote filesystem where frequent random I/O is costly\n",
    "- Choosing chunk_size (number of frames processed per batch):\n",
    "  - Start with 500â€“2000 as a general rule of thumb; 1000 is a balanced default\n",
    "  - Increase if you have plenty of RAM (fewer I/O operations, faster overall)\n",
    "  - Decrease if you observe high memory usage, swapping, or OOM errors\n",
    "\n",
    "Quick mental model for memory needs\n",
    "- Per-batch memory = (n_features Ã— bytes_per_feature) Ã— chunk_size_frames + overhead\n",
    "- Examples: contacts often use 1 byte/feature; float32 distances use 4 bytes/feature\n",
    "- Aim for the batch to stay well below ~50% of available RAM to leave room for temporary arrays and the OS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 2RJY:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Creating Zarr cache: ./cache/protein_extended.dask.zarr\n",
      "  ðŸ” Analyzing trajectory dimensions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ðŸ“Š Counting frames: 10it [00:00, 39.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ðŸ“ Trajectory: 9368 frames Ã— 1027 atoms\n",
      "  ðŸ’¾ Writing trajectory data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ðŸ“ Processing chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 11.40it/s]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Cache created: ./cache/protein_extended.dask.zarr\n",
      "  ðŸ“Š Size: 87.4 MB\n",
      "\n",
      "Loaded 1 systems with 1 total trajectories:\n",
      "  2RJY: 1 trajectories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Initialize pipeline and load trajectory data\n",
    "pipeline = PipelineManager(use_memmap=True, chunk_size=1000)\n",
    "pipeline.trajectory.load_trajectories(data_input=\"../../data/2RJY/\")\n",
    "pipeline.trajectory.add_labels(traj_selection=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Feature Computation\n",
    "\n",
    "Raw atomic coordinates are sensitive to molecular rotation and translation, making direct comparison between frames problematic. Pairwise residue distances and contacts provide rotation/translation-invariant descriptors that capture the essential physics of protein structure. \n",
    "\n",
    "The distances default is a residue-residue metric. So all atom-atom distance between 2 residues are calculated and the closest heavy atom distance (without Hydrogen) is taken.\n",
    "\n",
    "The contacts used here in the \"contacts\" feature is a static boolean value. So if the residue-residue distance is lower the threshold, the contact-value is true, else it is false. It is kind of a representation, if two residues interact with each other or not.\n",
    "\n",
    "The 4.5 Ã… cutoff encompasses typical ranges for non-bonded interactions. It is a classical default, which is for example also used in mdciao or MDAnalysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing distances:   0%|          | 0/1 [00:00<?, ?trajectories/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1953 residue pairs for 64 residues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing traj <DaskMDTrajectory with 9368 frames, 1027 atoms, 64 residues, and PBC (openmm format)>:  10%|â–ˆ         | 1/10 [00:01<00:15,  1.74s/chunks]\n",
      "Processing traj <DaskMDTrajectory with 9368 frames, 1027 atoms, 64 residues, and PBC (openmm format)>:  10%|â–ˆ         | 1/10 [00:01<00:15,  1.74s/chunks]\n",
      "Computing distances:   0%|          | 0/1 [00:01<?, ?trajectories/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# TODO: Reference\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Compute distance and contact features\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m pipeline.feature.add.contacts(cutoff=\u001b[32m4.5\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mdxplain/lib/python3.12/site-packages/mdxplain/feature/services/feature_add_service.py:119\u001b[39m, in \u001b[36mFeatureAddService.distances\u001b[39m\u001b[34m(self, excluded_neighbors, traj_selection, force, force_original)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03mAdd distances feature type.\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m \u001b[33;03mMissing pairs (due to chain breaks) are handled automatically.\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    118\u001b[39m feature_type = Distances(excluded_neighbors=excluded_neighbors)\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipeline_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraj_selection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraj_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_original\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_original\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mdxplain/lib/python3.12/site-packages/mdxplain/feature/managers/feature_manager.py:252\u001b[39m, in \u001b[36mFeatureManager.add_feature\u001b[39m\u001b[34m(self, pipeline_data, feature_type, traj_selection, force, force_original)\u001b[39m\n\u001b[32m    247\u001b[39m FeatureValidationHelper.validate_computation_requirements(\n\u001b[32m    248\u001b[39m     pipeline_data, feature_type\n\u001b[32m    249\u001b[39m )\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# Create FeatureData objects per trajectory\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_feature_data_per_trajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpipeline_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_original\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# Update memory estimate based on computed features\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_key \u001b[38;5;129;01min\u001b[39;00m pipeline_data.feature_data:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mdxplain/lib/python3.12/site-packages/mdxplain/feature/managers/feature_manager.py:513\u001b[39m, in \u001b[36mFeatureManager._create_feature_data_per_trajectory\u001b[39m\u001b[34m(self, pipeline_data, feature_type, feature_key, traj_indices, force_original)\u001b[39m\n\u001b[32m    504\u001b[39m feature_data = FeatureData(\n\u001b[32m    505\u001b[39m     feature_type=feature_type,\n\u001b[32m    506\u001b[39m     use_memmap=\u001b[38;5;28mself\u001b[39m.use_memmap,\n\u001b[32m   (...)\u001b[39m\u001b[32m    509\u001b[39m     trajectory_name=trajectory_name,\n\u001b[32m    510\u001b[39m )\n\u001b[32m    512\u001b[39m \u001b[38;5;66;03m# Compute feature for single trajectory\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m513\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_and_store_single_trajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpipeline_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_original\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# Store the feature data\u001b[39;00m\n\u001b[32m    518\u001b[39m pipeline_data.feature_data[feature_key][traj_idx] = feature_data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mdxplain/lib/python3.12/site-packages/mdxplain/feature/managers/feature_manager.py:553\u001b[39m, in \u001b[36mFeatureManager._compute_and_store_single_trajectory\u001b[39m\u001b[34m(self, pipeline_data, feature_data, feature_type, traj_idx, force_original)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    532\u001b[39m \u001b[33;03mCompute and store feature for single trajectory.\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    550\u001b[39m \u001b[33;03m    Computes and stores data in feature_data\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    552\u001b[39m \u001b[38;5;66;03m# Compute using helper for single trajectory\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m single_data, single_metadata = \u001b[43mFeatureComputationHelper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_computation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpipeline_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_original\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[38;5;66;03m# Store results and bind methods\u001b[39;00m\n\u001b[32m    558\u001b[39m FeatureComputationHelper.store_computation_results(\n\u001b[32m    559\u001b[39m     feature_data, single_data, single_metadata\n\u001b[32m    560\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mdxplain/lib/python3.12/site-packages/mdxplain/feature/helper/feature_computation_helper.py:204\u001b[39m, in \u001b[36mFeatureComputationHelper.execute_computation\u001b[39m\u001b[34m(pipeline_data, feature_data, feature_type, traj_idx, force_original)\u001b[39m\n\u001b[32m    202\u001b[39m single_traj = pipeline_data.trajectory_data.trajectories[traj_idx]\n\u001b[32m    203\u001b[39m single_labels = pipeline_data.trajectory_data.res_label_data[traj_idx]\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeature_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_traj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msingle_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mdxplain/lib/python3.12/site-packages/mdxplain/feature/feature_type/distances/distances.py:168\u001b[39m, in \u001b[36mDistances.compute\u001b[39m\u001b[34m(self, input_data, feature_metadata)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.calculator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    165\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCalculator not initialized. Call init_calculator() first.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    166\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcalculator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexcluded_neighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexcluded_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mres_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mdxplain/lib/python3.12/site-packages/mdxplain/feature/feature_type/distances/distance_calculator.py:139\u001b[39m, in \u001b[36mDistanceCalculator.compute\u001b[39m\u001b[34m(self, input_data, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m total_frames, distances = \u001b[38;5;28mself\u001b[39m._setup_computation(trajectory, excluded_neighbors, res_metadata)\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# Process single trajectory\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m distances, res_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_trajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# Consistency check: res_list should match self.pairs\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_pair_consistency(res_list)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mdxplain/lib/python3.12/site-packages/mdxplain/feature/feature_type/distances/distance_calculator.py:522\u001b[39m, in \u001b[36mDistanceCalculator._process_trajectory\u001b[39m\u001b[34m(self, traj, distances)\u001b[39m\n\u001b[32m    519\u001b[39m frames_to_process = \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.chunk_size, traj.n_frames - frame_start)\n\u001b[32m    521\u001b[39m \u001b[38;5;66;03m# Use our precomputed pairs list for ALL residue pairs (except self-pairs)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m dist, res_list = \u001b[43mmd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_contacts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mframe_start\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_start\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_to_process\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontacts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use our generated pairs list\u001b[39;49;00m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheme\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclosest-heavy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;66;03m# Direct assignment - dist is already in condensed format\u001b[39;00m\n\u001b[32m    529\u001b[39m distances[frame_start : frame_start + frames_to_process] = dist\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mdxplain/lib/python3.12/site-packages/mdtraj/geometry/contact.py:256\u001b[39m, in \u001b[36mcompute_contacts\u001b[39m\u001b[34m(traj, contacts, scheme, ignore_nonprotein, periodic, soft_min, soft_min_beta)\u001b[39m\n\u001b[32m    244\u001b[39m     atom_pairs.extend(\n\u001b[32m    245\u001b[39m         \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m    246\u001b[39m             itertools.product(\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m         ),\n\u001b[32m    251\u001b[39m     )\n\u001b[32m    252\u001b[39m     n_atom_pairs_per_residue_pair.append(\n\u001b[32m    253\u001b[39m         residue_lens[pair[\u001b[32m0\u001b[39m]] * residue_lens[pair[\u001b[32m1\u001b[39m]],\n\u001b[32m    254\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m atom_distances = \u001b[43mmd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matom_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiodic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperiodic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# now squash the results based on residue membership\u001b[39;00m\n\u001b[32m    259\u001b[39m n_residue_pairs = \u001b[38;5;28mlen\u001b[39m(residue_pairs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mdxplain/lib/python3.12/site-packages/mdtraj/geometry/distance.py:170\u001b[39m, in \u001b[36mcompute_distances\u001b[39m\u001b[34m(traj, atom_pairs, periodic, opt)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_distances\u001b[39m(traj, atom_pairs, periodic=\u001b[38;5;28;01mTrue\u001b[39;00m, opt=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    147\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the distances between pairs of atoms in each frame.\u001b[39;00m\n\u001b[32m    148\u001b[39m \n\u001b[32m    149\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m \u001b[33;03m        The distance, in each frame, between each pair of atoms.\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute_distances_core\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43matom_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43munitcell_vectors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m.\u001b[49m\u001b[43munitcell_vectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mperiodic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperiodic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mdxplain/lib/python3.12/site-packages/mdtraj/geometry/distance.py:125\u001b[39m, in \u001b[36mcompute_distances_core\u001b[39m\u001b[34m(positions, atom_pairs, unitcell_vectors, periodic, opt)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt:\n\u001b[32m    124\u001b[39m     out = np.empty((xyz.shape[\u001b[32m0\u001b[39m], pairs.shape[\u001b[32m0\u001b[39m]), dtype=np.float32)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[43m_geometry\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_dist_mic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m        \u001b[49m\u001b[43morthogonal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# TODO: Reference\n",
    "# Compute distance and contact features\n",
    "pipeline.feature.add.distances()\n",
    "pipeline.feature.add.contacts(cutoff=4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Feature Selection\n",
    "\n",
    "Why focus on contacts here\n",
    "- Interaction patterns can often reveal mechanistic differences between conformations more clearly than the magnitude of distance changes alone.\n",
    "- Contacts directly report formation/breaking of specific interactions, mapping naturally to hypotheses, mutational tests, and functional interpretation.\n",
    "- Therefore, in this tutorial we prioritize a contact-based analysis to highlight how interaction networks change across states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created feature selector: 'contacts_only'\n",
      "Added to selector 'contacts_only': contacts -> 'all' (use_reduced=False, common_denominator=True, traj_selection=all, require_all_partners=False)\n",
      "Applied feature selector 'contacts_only' with reference trajectory 0 successfully\n"
     ]
    }
   ],
   "source": [
    "# Create feature selector focused on contact analysis\n",
    "# We create a selector and select the contacts of all available atoms / residues in this case\n",
    "# After this step, we call select to create the feature-matrix in our pipeline\n",
    "pipeline.feature_selector.create(\"contacts_only\")\n",
    "pipeline.feature_selector.add.contacts(\"contacts_only\", \"all\")\n",
    "pipeline.feature_selector.select(\"contacts_only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Dimensionality Reduction\n",
    "\n",
    "The contact matrix contains (NÂ² - N)/2 features (one per residue pair), creating a high-dimensional space where conventional clustering algorithms fail due to the \"curse of dimensionality.\" \n",
    "In high dimensions, all points become approximately equidistant, and noise dominates meaningful signals. Therefore we need to reduce the number of dimensions using a dimension reduction method.\n",
    "\n",
    "A classical way doing this is a PCA, which tries to neglect correlative information, i.e. redundancy and catch the axis with the most variant linear combinations of features.\n",
    "Cause MD data are often non-linear, a kernel PCA is the logical update to catch non-linear combinations of features.\n",
    "\n",
    "Cause we are doing a contact analysis, it could make sense to build a principle component space based directly on this data. Therefore we are doing a contact kernel PCA.\n",
    "\n",
    "This is basically a RBF kernel on the contact maps. This is equivalent to a hamming distance kernel. So we count the number of differences. \n",
    "\n",
    "So the first component holds the non-linear dynamic motion with the biggest change in the interaction pattern of the protein, the second the 2nd biggest and so on, which is a good space to cluster conformational states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating binary data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18296/18296 [00:00<00:00, 90723.68chunks/s]\n",
      "Computing kernel matrix rows:   0%|          | 0/19 [00:00<?, ?chunks/s]\n",
      "Computing kernel matrix rows: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  4.12chunks/s]\n",
      "Computing kernel matrix rows: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  4.12chunks/s]\n",
      "Computing row sums: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 220.53chunks/s]\n",
      "Computing row sums: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 220.53chunks/s]\n",
      "Computing col sums: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 164.68chunks/s]\n",
      "Computing col sums: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 164.68chunks/s]\n",
      "Centering kernel matrix: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 24.43chunks/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting eigendecomposition for 10 components...\n",
      "  Matrix-vector products: 10\n",
      "  Matrix-vector products: 20\n",
      "  Matrix-vector products: 30\n",
      "  Matrix-vector products: 20\n",
      "  Matrix-vector products: 30\n",
      "  Matrix-vector products: 40\n",
      "Eigendecomposition completed after 40 matrix-vector products\n",
      "Decomposition 'contact_kernel_pca' with name 'ContactKernelPCA' for selection 'contacts_only' computed successfully. Data reduced from (9368, 1953) to (9368, 10).\n",
      "  Matrix-vector products: 40\n",
      "Eigendecomposition completed after 40 matrix-vector products\n",
      "Decomposition 'contact_kernel_pca' with name 'ContactKernelPCA' for selection 'contacts_only' computed successfully. Data reduced from (9368, 1953) to (9368, 10).\n"
     ]
    }
   ],
   "source": [
    "# TODO: Reference\n",
    "# Apply Contact Kernel PCA\n",
    "pipeline.decomposition.add.contact_kernel_pca(\n",
    "    n_components=10, \n",
    "    gamma=0.001, \n",
    "    selection_name=\"contacts_only\", \n",
    "    decomposition_name=\"ContactKernelPCA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Conformational State Identification\n",
    "\n",
    "The goal of this step is to group the simulation trajectory data into a set of distinct conformational states using a clustering algorithm.\n",
    "\n",
    "A primary challenge in this analysis is that conventional clustering methods, such as k-means, are problematic for this type of data. Such methods presuppose spherical cluster shapes and require the number of clusters to be known. Neither assumption is appropriate for the complex and unknown nature of conformational landscapes.\n",
    "\n",
    "To address these limitations, we employ a density based clustering in this example the Density Peak Advanced (DPA) algorithm. DPA identifies cluster centers as high-density regions that are separated by low-density boundaries, which allows it to automatically determine the optimal number of states. A Z-score(Z-value) threshold of 2.0 is used to achieve a balance between the sensitivity needed to resolve distinct conformational biases and the robustness required to filter out the thermal noise inherent to molecular dynamics simulations.\n",
    "\n",
    "In our daily analysis of MD data, we find that DPA is not only highly effective but also more straightforward to apply than other density-based methods, such as DBSCAN or HDBSCAN. Its primary advantage lies in its practical approach to hyperparameter tuning. While the DPA algorithm includes several configurable parameters, we have found that in practice, default values are typically sufficient for the clustering of conformational states. The Z-value can the be used to control the desired level of clustering granularity. Higher Z-values produce a coarser clustering with fewer, more distinct states, while lower values yield a more fine-grained result. This provides us with an intuitive mechanism to adjust the clustering resolution, circumventing the need to optimize the more abstract hyperparameters, such as eps and min_samples, required by (H)DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 'DPA' completed successfully.\n",
      "Found 6 clusters for 9368 frames.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Reference\n",
    "\n",
    "# DPA clustering on decomposed data\n",
    "pipeline.clustering.add.dpa(\n",
    "    selection_name=\"ContactKernelPCA\",\n",
    "    cluster_name=\"DPA\",\n",
    "    Z=3.0,\n",
    "    force=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Comparative Analysis Setup\n",
    "\n",
    "Having identified conformational states, we now address the key biological question: which molecular interactions define each state? \n",
    "\n",
    "Data selectors organize trajectory frames by cluster membership, enabling systematic comparison between states. \n",
    "\n",
    "The one-vs-rest strategy identifies features that distinguish each state from all others, revealing the defining characteristics rather than just pairwise differences. \n",
    "\n",
    "This approach provides a comprehensive molecular fingerprint for each conformational state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data selectors for each cluster\n",
    "n_clusters = pipeline.data.cluster_data[\"DPA\"].get_n_clusters()\n",
    "for i in range(n_clusters):\n",
    "    pipeline.data_selector.create(f\"cluster_{i}\")\n",
    "    pipeline.data_selector.select_by_cluster(f\"cluster_{i}\", \"DPA\", [i])\n",
    "\n",
    "# Create one-vs-all comparison\n",
    "cluster_names = [f\"cluster_{i}\" for i in range(n_clusters)]\n",
    "pipeline.comparison.create_comparison(\n",
    "    name=\"cluster_comparison\",\n",
    "    mode=\"one_vs_rest\",\n",
    "    feature_selector=\"contacts_only\",\n",
    "    data_selectors=cluster_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 7: Identifying Key Contacts with a Decision Tree**\n",
    "\n",
    "So, after we set up our \"one-vs-rest\" comparisons in Step 6. We now have to ask the question of, how do we actually find the molecular interactions that define each state? For this, we will use decision trees.\n",
    "\n",
    "A decision tree is a great choice for this task because it creates a flowchart or tree of simple \"yes/no\" questions to classify the data. This is ideal for our purposes, cause tt works perfectly with our binary contact data (a contact is either formed or not) and is easy to interpret. It generates a set of human-readable rules that explain what makes a state unique.\n",
    "\n",
    "A crucial point is, that we are not trying to build a perfect model to predict the state of new, unseen data, but use it as an explanatory tool. \n",
    "Our goal is to have the model describe the data we already have as accurately as possible.\n",
    "\n",
    "We want it to tell us which contacts are the most important for distinguishing the conformational states we've found. Therefore, the traditional concern about \"overfitting\" doesn't apply here, cause we are interested in the features that define our specific dataset.\n",
    "\n",
    "To ensure the rules are simple and easy to understand, we limit the tree's complexity by setting `max_depth=3`. This forces the model to use only the most dominant and influential contacts to classify a state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating frame selection: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 112.51chunks/s]\n",
      "\n",
      "Creating frame selection: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 115.01chunks/s]\n",
      "\n",
      "Creating frame selection: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 115.20chunks/s]\n",
      "\n",
      "Creating frame selection: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 115.35chunks/s]\n",
      "\n",
      "Creating frame selection: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 113.62chunks/s]\n",
      "\n",
      "Creating frame selection: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 114.48chunks/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Reference\n",
    "\n",
    "# Analyze feature importance\n",
    "pipeline.feature_importance.add.decision_tree(\n",
    "    comparison_name=\"cluster_comparison\",\n",
    "    analysis_name=\"feature_importance\",\n",
    "    max_depth=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 8: Identifying the Top Contacts**\n",
    "\n",
    "The decision tree analysis provides a feature importance score for every contact. `scikit-learn` calculates this value as the Gini Importance or the Entropy,  depending on which `criterion` was used to create the trees. Default is `gini`.\n",
    "This score measures how effective a contact is at creating \"purer\" decision nodes in the tree. In other words, how well it helps to cleanly separate one state from all the others.\n",
    "\n",
    "These scores are normalized to a range between 0.0 and 1.0. A higher score means more important feature in the fingerprint of this cluster.\n",
    "\n",
    "To focus on the most essential information, we select the 3 contacts with the highest feature importance scores. These few contacts represent the core of the fingerprint for that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 features distinguishing Cluster 0:\n",
      "  1. PRO17-SER43: 0.537\n",
      "  2. ALA26-GLY32: 0.379\n",
      "  3. PHE16-SER43: 0.071\n",
      "\n",
      "Top 3 features distinguishing Cluster 1:\n",
      "  1. ALA26-PRO35: 0.390\n",
      "  2. PRO17-SER43: 0.329\n",
      "  3. PRO35-LYS38: 0.096\n",
      "\n",
      "Top 3 features distinguishing Cluster 2:\n",
      "  1. LEU13-ARG31: 0.830\n",
      "  2. MET53-ARG55: 0.080\n",
      "  3. THR24-LEU29: 0.078\n"
     ]
    }
   ],
   "source": [
    "# TODO: Reference\n",
    "\n",
    "# Get top features for each cluster vs rest\n",
    "for i in range(min(3, n_clusters)):  # Show first 3 clusters\n",
    "    sub_comparison_name = f\"cluster_{i}_vs_rest\"\n",
    "    \n",
    "    top_features = pipeline.feature_importance.get_top_features(\n",
    "        analysis_name=\"feature_importance\",\n",
    "        comparison_identifier=sub_comparison_name,\n",
    "        n=3\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTop 3 features distinguishing Cluster {i}:\")\n",
    "    for j, feature_info in enumerate(top_features, 1):\n",
    "        print(f\"  {j}. {feature_info['feature_name']}: {feature_info['importance_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 9: Saving and loading the pipeline**\n",
    "\n",
    "In mdxplain you can save a whole pipeline with all your data and calculations and load it later again. Just do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.save(\"cache/example_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pipeline = PipelineManager()\n",
    "loaded_pipeline.load(\"cache/example_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 10: Info Printing**\n",
    "\n",
    "With `print_info()` you can get a lot of informations about the content of your pipeline. After or before the loading. To know, whats in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= PIPELINE INFORMATION =======\n",
      "\n",
      "--- Trajectory Data ---\n",
      "Loaded 1 trajectories:\n",
      "  [0] 2RJY_protein_protein_extended: 9368 frames\n",
      "\n",
      "--- Feature Data ---\n",
      "=== Feature Information ===\n",
      "Feature Types: 2 (distances, contacts)\n",
      "\n",
      "--- distances ---\n",
      "Trajectory 0:\n",
      "=== FeatureData ===\n",
      "Feature Type: Distances\n",
      "Original Data: 9368 frames x 1953 features\n",
      "Feature Metadata: 1953 feature definitions\n",
      "\n",
      "--- contacts ---\n",
      "Trajectory 0:\n",
      "=== FeatureData ===\n",
      "Feature Type: Contacts\n",
      "Original Data: 9368 frames x 1953 features\n",
      "Feature Metadata: 1953 feature definitions\n",
      "\n",
      "--- Feature Selection Data ---\n",
      "=== FeatureSelectorData Information ===\n",
      "FeatureSelectorData Names: 1 (contacts_only)\n",
      "\n",
      "--- contacts_only ---\n",
      "=== FeatureSelectorData ===\n",
      "Name: contacts_only\n",
      "Feature Types: 1 (contacts)\n",
      "Total Selections: 1\n",
      "Reference Trajectory: 0\n",
      "Matrix Columns: 1953\n",
      "Selection Results: Available for 1 feature types (contacts)\n",
      "\n",
      "--- Clustering Data ---\n",
      "=== ClusteringData Information ===\n",
      "ClusteringData Names: 1 (DPA)\n",
      "\n",
      "--- DPA ---\n",
      "=== ClusterData ===\n",
      "Cluster Type: DPA\n",
      "Number of Clusters: 6\n",
      "Number of Frames: 9368\n",
      "Hyperparameters: Z=3.0, metric=euclidean, affinity=precomputed, density_algo=PAk, k_max=1000, D_thr=23.92812698, dim_algo=twoNN, blockAn=True, block_ratio=20, frac=1.0, halos=False, method=standard, sample_size=9368, knn_neighbors=5, force=True\n",
      "Frame Mapping: 9368 frames from 1 trajectories\n",
      "\n",
      "--- Decomposition Data ---\n",
      "=== DecompositionData Information ===\n",
      "DecompositionData Names: 1 (ContactKernelPCA)\n",
      "\n",
      "--- ContactKernelPCA ---\n",
      "=== DecompositionData ===\n",
      "Decomposition Type: CONTACT_KERNEL_PCA\n",
      "Transformed Data: 9368 frames x 10 components\n",
      "Hyperparameters: n_components=10, kernel=rbf, gamma=0.001, use_nystrom=False, n_landmarks=2000, random_state=None, kernel_description=rbf on binary data (Hamming distance), contact_kernel=True, binary_data=True\n",
      "Frame Mapping: 9368 frames from 1 trajectories\n",
      "\n",
      "--- Data Selector Data ---\n",
      "=== DataSelectorData Information ===\n",
      "DataSelectorData Names: 6 (cluster_0, cluster_1, cluster_2, cluster_3, cluster_4, cluster_5)\n",
      "\n",
      "--- cluster_0 ---\n",
      "=== DataSelectorData ===\n",
      "Name: cluster_0\n",
      "Selected Frames: 279 frames from 1 trajectories\n",
      "Selection Type: cluster\n",
      "Frame Distribution: traj0:1667-2452 (279)\n",
      "\n",
      "--- cluster_1 ---\n",
      "=== DataSelectorData ===\n",
      "Name: cluster_1\n",
      "Selected Frames: 819 frames from 1 trajectories\n",
      "Selection Type: cluster\n",
      "Frame Distribution: traj0:0-4626 (819)\n",
      "\n",
      "--- cluster_2 ---\n",
      "=== DataSelectorData ===\n",
      "Name: cluster_2\n",
      "Selected Frames: 2 frames from 1 trajectories\n",
      "Selection Type: cluster\n",
      "Frame Distribution: traj0:2817-3104 (2)\n",
      "\n",
      "--- cluster_3 ---\n",
      "=== DataSelectorData ===\n",
      "Name: cluster_3\n",
      "Selected Frames: 4901 frames from 1 trajectories\n",
      "Selection Type: cluster\n",
      "Frame Distribution: traj0:3983-9367 (4901)\n",
      "\n",
      "--- cluster_4 ---\n",
      "=== DataSelectorData ===\n",
      "Name: cluster_4\n",
      "Selected Frames: 1038 frames from 1 trajectories\n",
      "Selection Type: cluster\n",
      "Frame Distribution: traj0:1201-3888 (1038)\n",
      "\n",
      "--- cluster_5 ---\n",
      "=== DataSelectorData ===\n",
      "Name: cluster_5\n",
      "Selected Frames: 2329 frames from 1 trajectories\n",
      "Selection Type: cluster\n",
      "Frame Distribution: traj0:1-9364 (2329)\n",
      "\n",
      "--- Comparison Data ---\n",
      "=== Comparison Information ===\n",
      "Comparison Names: 1 (cluster_comparison)\n",
      "\n",
      "--- cluster_comparison ---\n",
      "=== ComparisonData ===\n",
      "Name: cluster_comparison\n",
      "Comparison Mode: one_vs_rest\n",
      "Feature Selector: contacts_only\n",
      "Data Selectors: 6 (cluster_0, cluster_1, cluster_2, cluster_3, cluster_4, cluster_5)\n",
      "Sub-Comparisons: 6 (cluster_0_vs_rest, cluster_1_vs_rest, cluster_2_vs_rest, cluster_3_vs_rest, cluster_4_vs_rest, cluster_5_vs_rest)\n",
      "\n",
      "--- Feature Importance Data ---\n",
      "=== FeatureImportanceData Information ===\n",
      "FeatureImportanceData Names: 1 (feature_importance)\n",
      "\n",
      "--- feature_importance ---\n",
      "=== FeatureImportanceData ===\n",
      "Name: feature_importance\n",
      "Analyzer Type: decision_tree\n",
      "Comparison: cluster_comparison\n",
      "Sub-Comparisons: 6 (cluster_0_vs_rest, cluster_1_vs_rest, cluster_2_vs_rest, cluster_3_vs_rest, cluster_4_vs_rest, cluster_5_vs_rest)\n",
      "Features Analyzed: 1953\n",
      "Top Feature Overall: Feature 266 (avg importance: 0.1979)\n",
      "Top 3 Features: Feature 266 (0.198), Feature 927 (0.189), Feature 679 (0.160)\n",
      "\n",
      "======= END PIPELINE INFORMATION =======\n",
      "\n",
      "Pipeline Summary: 1 trajectories, 2 feature types, 1 clusterings\n"
     ]
    }
   ],
   "source": [
    "loaded_pipeline.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "This tutorial walked through an endâ€‘toâ€‘end, contactâ€‘focused workflow: Feature engineering of residue contacts, dimensionality reduction with Contact Kernel PCA, and clustering with DPA, to identify conformational states and the specific interactions that define them. \n",
    "\n",
    "The key strength of mdxplain is its modular pipeline builder: each step can be swapped or extended without changing the overall flow, and all intermediate results are collected and reused via `pipeline.data`.\n",
    "\n",
    "Beyond the minimal example, mdxplain supports a broader feature set (e.g., DSSP/secondary structure, torsion angles, SASA, distances, raw coordinates) and multiple alternatives for dimensionality reduction and clustering. \n",
    "\n",
    "By standardizing data flow and bookkeeping, the library streamlines building and saving analyses. \n",
    "\n",
    "Common applications include:\n",
    "- Exporting feature matrices for downstream machineâ€‘learning models.\n",
    "- Tagâ€‘based comparisons across conditions (e.g., wild type vs mutant, ligandâ€‘bound vs apo) to identify discriminative features (contacts, secondary structure, SASA) and explain structural/dynamical effects.\n",
    "- Estimating state transition counts and preparing inputs for Markov state models.\n",
    "- Computing contact frequencies or other statistical feature properties and their differences across systems.\n",
    "- Doing RMSD and RMSF analysis for basic insights into the systems.\n",
    "- Paralell working on many trajectories at once.\n",
    "- Having many different metrices and features of many different trajectories at one place.\n",
    "\n",
    "And many more.\n",
    "\n",
    "To extend the workflow, `pipeline.analysis.structure` provides multiple RMSD/RMSF metrics, and `pipeline.analysis.feature.*` offers perâ€‘feature statistics (e.g., contact frequencies, transition counts). Combining these with state discovery enables richer, multiâ€‘faceted analyses that connect structure, dynamics, and feature statistics.\n",
    "\n",
    "### Limitations and outlook\n",
    "\n",
    "The quality of any analysis depends on adequate conformational sampling and the suitability of the chosen descriptors. Hyperparameters such as contact cutoffs, the number of components, and clustering sensitivity may require light tuning across systems.\n",
    "\n",
    "Also there are thousands of different other methods one could use for the analysis. But for this cases, mdxplain serves you with the necessary feature-data in an memory efficient, performant and streamlined way. \n",
    "\n",
    "But with this, there is another limitation. Disk space. If you use your disk for big analysis, cause your trajectory and feature data does not fit in RAM, you need disk space. For hugh system this can also become a problem. \n",
    "\n",
    "## Conclusion\n",
    "\n",
    "mdxplain lowers the effort to move from raw trajectories to interpretable, testable insights by simplifying the composition, execution, and persistence of complex structural analysis pipelines. Its modular design and extensibility make it a practical tool across structural biology use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Crystal Structure of a pH-Stabilized Mutant of Villin Headpiece, Jianmin Meng and C. James McKnight, Biochemistry 2008 47 (16), 4644-4650, DOI: 10.1021/bi7022738\n",
    "\n",
    "[2] ROCKLIN, Gabriel J., et al. Global analysis of protein folding using massively parallel design, synthesis, and testing. Science, 2017, 357. Jg., Nr. 6347, S. 168-175.\n",
    "\n",
    "[3] Melvin RL, Godwin RC, Xiao J, Thompson WG, Berenhaut KS, Salsbury FR Jr. Uncovering Large-Scale Conformational Change in Molecular Dynamics without Prior Knowledge. J Chem Theory Comput. 2016 Dec 13;12(12):6130-6146. doi: 10.1021/acs.jctc.6b00757\n",
    "\n",
    "[4] H. Lei,C. Wu,H. Liu, & Y. Duan,  Folding free-energy landscape of villin headpiece subdomain from molecular dynamics simulations, Proc. Natl. Acad. Sci. U.S.A. 104 (12) 4925-4930, https://doi.org/10.1073/pnas.0608432104 (2007).\n",
    "\n",
    "[5] Ensign DL, Kasson PM, Pande VS. Heterogeneity even at the speed limit of folding: large-scale molecular dynamics study of a fast-folding variant of the villin headpiece. J Mol Biol. 2007 Nov 30;374(3):806-16. doi: 10.1016/j.jmb.2007.09.069. Epub 2007 Sep 29. Erratum in: J Mol Biol. 2008 Nov 21;383(4):935. PMID: 17950314; PMCID: PMC3689540.\n",
    "\n",
    "[6] Roy GonzÃ¡lez-AlemÃ¡n, Daniel Platero-Rochart, David HernÃ¡ndez-Castillo, Erix W HernÃ¡ndez-RodrÃ­guez, Julio Caballero, Fabrice Leclerc, Luis Montero-Cabrera, BitQT: a graph-based approach to the quality threshold clustering of molecular dynamics, Bioinformatics, Volume 38, Issue 1, January 2022, Pages 73â€“79, https://doi.org/10.1093/bioinformatics/btab595\n",
    "\n",
    "[7] WANG, Ercheng, et al. A novel folding pathway of the villin headpiece subdomain HP35. Physical Chemistry Chemical Physics, 2019, 21. Jg., Nr. 33, S. 18219-18226."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Disclaimer\n",
    "\n",
    "This notebook was written with the suppport of Github Copilot with OpenAI GPT-5 and Google Gemini 2.5 Pro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdxplain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
